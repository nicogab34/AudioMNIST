{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import add_to_syspath\n",
    "from audiomnist.io.read_dataset import load_alexnet_dataset\n",
    "from audiomnist.models.autoencoder_spectrogram import build_model as build_model_autoencoder\n",
    "from audiomnist.models.alexnet import build_model as build_model_alexnet\n",
    "from audiomnist.train.autoencoder_spectrogram import get_epoch_checkpoint\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import lucid.modelzoo.vision_models as models\n",
    "from lucid.misc.io import show\n",
    "import lucid.optvis.objectives as objectives\n",
    "import lucid.optvis.param as param\n",
    "import lucid.optvis.render as render\n",
    "import lucid.optvis.transform as transform\n",
    "from lucid.modelzoo import vision_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_alexnet_dataset(\"../tf_data/spectrogram.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_autoencoder1 (Conv2D)   (None, 227, 227, 32)      320       \n",
      "_________________________________________________________________\n",
      "pool_autoencoder1 (MaxPoolin (None, 114, 114, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder2 (Conv2D)   (None, 114, 114, 16)      4624      \n",
      "_________________________________________________________________\n",
      "pool_autoencoder2 (MaxPoolin (None, 57, 57, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder3 (Conv2D)   (None, 57, 57, 8)         1160      \n",
      "_________________________________________________________________\n",
      "pool_autoencoder3 (MaxPoolin (None, 29, 29, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder4 (Conv2D)   (None, 29, 29, 8)         584       \n",
      "_________________________________________________________________\n",
      "up_autoencoder1 (UpSampling2 (None, 58, 58, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder5 (Conv2D)   (None, 58, 58, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_autoencoder2 (UpSampling2 (None, 116, 116, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder6 (Conv2D)   (None, 116, 116, 32)      4640      \n",
      "_________________________________________________________________\n",
      "up_autoencoder3 (UpSampling2 (None, 232, 232, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder7 (Conv2D)   (None, 232, 232, 1)       289       \n",
      "_________________________________________________________________\n",
      "crop (Cropping2D)            (None, 227, 227, 1)       0         \n",
      "=================================================================\n",
      "Total params: 12,785\n",
      "Trainable params: 12,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_autoencoder = build_model_autoencoder()\n",
    "model_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7ffef9274dd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = get_epoch_checkpoint(\"../models/autoencoder_spectrogram\", 50)\n",
    "model_autoencoder.load_weights(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 55, 55, 96)        11712     \n",
      "_________________________________________________________________\n",
      "leaky_relu1 (LeakyReLU)      (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "leaky_relu2 (LeakyReLU)      (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "leaky_relu3 (LeakyReLU)      (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 7, 7, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 5, 5, 256)         884992    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 5,834,826\n",
      "Trainable params: 5,834,122\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_alexnet = build_model_alexnet()\n",
    "model_alexnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ffef908f828> and <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7ffef908f710>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ffef908f828> and <tensorflow.python.keras.layers.advanced_activations.LeakyReLU object at 0x7ffef908f710>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ffef908fa20> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ffef908f828>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ffef908fa20> and <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7ffef908f828>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7ffef8f6f6d8> and <tensorflow.python.keras.layers.core.Flatten object at 0x7ffef8f6f470>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7ffef8f6f6d8> and <tensorflow.python.keras.layers.core.Flatten object at 0x7ffef8f6f470>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7ffef915c4e0> and <tensorflow.python.keras.layers.core.Dropout object at 0x7ffef8f45ef0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7ffef915c4e0> and <tensorflow.python.keras.layers.core.Dropout object at 0x7ffef8f45ef0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7ffef8eec3c8> and <tensorflow.python.keras.layers.core.Dropout object at 0x7ffef8f34160>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Checkpointable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7ffef8eec3c8> and <tensorflow.python.keras.layers.core.Dropout object at 0x7ffef8f34160>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.checkpointable.util.CheckpointLoadStatus at 0x7ffef8df36a0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = get_epoch_checkpoint(\"../models/alexnet\",19)\n",
    "model_alexnet.load_weights(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dataset.__iter__() is only supported when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-988aeacd0cae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workdir/2017duquesnej/miniconda3/envs/aud_interp/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workdir/2017duquesnej/miniconda3/envs/aud_interp/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       raise RuntimeError(\"dataset.__iter__() is only supported when eager \"\n\u001b[0m\u001b[1;32m    207\u001b[0m                          \"execution is enabled.\")\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dataset.__iter__() is only supported when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(image['data']).reshape((227,227)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoded = model_autoencoder.predict(np.array(image['data']).reshape((1,227,227,1)))\n",
    "plt.imshow(image_encoded.reshape((227,227)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = keras.Model(inputs=model_autoencoder.input,outputs=model_autoencoder.get_layer('conv_autoencoder4').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.71969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2677., 1382., 1386.,  460.,   66.,  124.,  200.,  154.,  199.,\n",
       "          80.]),\n",
       " array([  0.      ,  10.071969,  20.143938,  30.215906,  40.287876,\n",
       "         50.359844,  60.431812,  70.503784,  80.57575 ,  90.64772 ,\n",
       "        100.71969 ], dtype=float32),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_image = encoder_model.predict(np.array(image['data']).reshape((1,227,227,1)))\n",
    "encoded_image = encoded_image.reshape((29*29*8))\n",
    "print(max(encoded_image))\n",
    "plt.hist(encoded_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(29,29,8))\n",
    "x = inputs\n",
    "\n",
    "for i in range(7,len(model_autoencoder.layers)):\n",
    "    x = model_autoencoder.layers[i](x)\n",
    "\n",
    "for layer in model_alexnet.layers:\n",
    "    x = layer(x)\n",
    "\n",
    "complete_model = keras.Model(inputs=inputs,outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 29, 29, 8)         0         \n",
      "_________________________________________________________________\n",
      "up_autoencoder1 (UpSampling2 (None, 58, 58, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder5 (Conv2D)   (None, 58, 58, 16)        1168      \n",
      "_________________________________________________________________\n",
      "up_autoencoder2 (UpSampling2 (None, 116, 116, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder6 (Conv2D)   (None, 116, 116, 32)      4640      \n",
      "_________________________________________________________________\n",
      "up_autoencoder3 (UpSampling2 (None, 232, 232, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_autoencoder7 (Conv2D)   (None, 232, 232, 1)       289       \n",
      "_________________________________________________________________\n",
      "crop (Cropping2D)            (None, 227, 227, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 55, 55, 96)        11712     \n",
      "_________________________________________________________________\n",
      "leaky_relu1 (LeakyReLU)      (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 23, 23, 256)       614656    \n",
      "_________________________________________________________________\n",
      "leaky_relu2 (LeakyReLU)      (None, 23, 23, 256)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "leaky_relu3 (LeakyReLU)      (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 7, 7, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 5, 5, 256)         884992    \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 5,840,923\n",
      "Trainable params: 5,840,219\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "complete_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "complete_model.save('../models/decoder_alexnet/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v1.keras.experimental' from '/workdir/2017duquesnej/miniconda3/envs/aud_interp/lib/python3.7/site-packages/tensorflow/_api/v1/keras/experimental/__init__.py'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.summary.FileWriter is not compatible with eager execution. Use tf.contrib.summary instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-27b5ec3a7318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../logs/graphs/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workdir/2017duquesnej/miniconda3/envs/aud_interp/lib/python3.7/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       raise RuntimeError(\n\u001b[0;32m--> 360\u001b[0;31m           \u001b[0;34m\"tf.summary.FileWriter is not compatible with eager execution. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m           \"Use tf.contrib.summary instead.\")\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tf.summary.FileWriter is not compatible with eager execution. Use tf.contrib.summary instead."
     ]
    }
   ],
   "source": [
    "with K.get_session().as_default() as sess:\n",
    "    writer = tf.summary.FileWriter(\"../logs/graphs/\", tf.get_default_graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
